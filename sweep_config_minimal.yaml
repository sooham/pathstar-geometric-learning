# Minimal sweep configuration for quick testing
# Focuses on a few key hyperparameters
program: train.py
method: grid
metric:
  name: val/loss/overall
  goal: minimize

parameters:
  # Dataset parameters - small fixed values for quick iteration
  graph_d:
    values: [5000, 10000, 1000]
  graph_l:
    value: 5
  graph_vocab_size:
    value: '2max'
  graph_holdout_percentage:
    value: 0.5
  num_pause_tokens:
    value: [1,2,4]
  use_undirected:
    value: true
  use_directional_tokens:
    value: true
  
  # Model architecture parameters - sweep these
  n_layer:
    values: [12]
  n_head:
    values: [8]
  n_embd:
    values: [64]
  dropout:
    value: 0
  bias:
    value: false
  
  # Training hyperparameters - sweep learning rate
  learning_rate:
    value: 1e-3
  label_smoothing:
    value: 0.1
  weight_decay:
    value: 0.01
  beta1:
    value: 0.9
  beta2:
    value: 0.95
  grad_clip:
    value: 1.0
  
  # Learning rate schedule
  decay_lr:
    value: true
  warmup_frac:
    value: 0.10
  lr_decay_frac:
    value: 0.80
  min_lr:
    value: 6e-5
  
  # Fixed training parameters
  epochs:
    value: 5000  # Shorter for quick testing
  gradient_accumulation_steps:
    value: 1
  compile:
    value: false
  eval_interval:
    value: 100
  log_interval:
    value: 10

